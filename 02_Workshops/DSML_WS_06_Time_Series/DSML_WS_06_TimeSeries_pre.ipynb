{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DSML Workshop 06` - Working with Time Series Data\n",
    "\n",
    "In this workshop we focus on working with time series data, a very common data science task. We have covered some of this stuff implicitly in the previous workshop. Today we intend to go into detail on the time series capabilities of Python. We will introduce DateTime as the underlying time series implementation but focus mostly on Pandas.\n",
    "\n",
    "After covering the basics of time series in Python we will work hands-on with an electricity price dataset. At the end of this session you should:\n",
    "\n",
    "- Understand the Python `DateTime` Module and its implementation in `Pandas`\n",
    "- Read-in, manipulate, index and group time series data\n",
    "- Extract common time series features such as day-of-week, hour-of-day and weekday/weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, time, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DateTime`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series work very differently from standard numbers series such as integer series. You need special rules to perform operations on them. For this Python provides the necessary tools such as the built-in libraries `datetime` and `dateutil` or NumPy's `datetime64`. You can read up on these here: https://docs.python.org/3/library/datetime.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `datetime.date`: An idealized naive date, assuming the current Gregorian calendar always was, and always will be, in effect. Attributes: year, month, and day.\n",
    "\n",
    "- `datetime.time`: An idealized time, independent of any particular day, assuming that every day has exactly `24*60*60` seconds (there is no notion of “leap seconds” here). Attributes: hour, minute, second, microsecond, and tzinfo.\n",
    "\n",
    "- `datetime.datetime`: A combination of a date and a time. Attributes: year, month, day, hour, minute, second, microsecond, and tzinfo.\n",
    "\n",
    "- `datetime.timedelta`: A duration expressing the difference between two date, time, or datetime instances to microsecond resolution.\n",
    "\n",
    "- `datetime.tzinfo`: An abstract base class for time zone information objects. These are used by the datetime and time classes to provide a customizable notion of time adjustment (for example, to account for time zone and/or daylight saving time).\n",
    "\n",
    "- `datetime.timezone`: A class that implements the tzinfo abstract base class as a fixed offset from the UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a datetime object\n",
    "date1 = datetime(year=2020, month=5, day=13, hour=12, minute= 29, second=59, microsecond=109262)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the type\n",
    "type(date1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and a second one\n",
    "date2 = datetime(year=2020, month=5, day=14, hour=16, minute= 1, second=59, microsecond=109262)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform oparations on these tow datetime objects: A timedelta object results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can perform oparations on these two datetime objects: a timedelta object results\n",
    "delta = date2 - date1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print delta\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the type of delta\n",
    "type(delta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A powerful extension of `DateTime` is the `dateutil` module which allows you to parse date and time information that comes in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "date3 = parser.parse(\"13th of May, 2020\")\n",
    "date4 = parser.parse(\"13/05/2020\")\n",
    "\n",
    "print(date3)\n",
    "print(date4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of datetime and dateutil lie in their flexibility and easy syntax: you can use these objects and their built-in methods to easily perform nearly any operation you might be interested in. They have their weaknesses when you wish to work with large arrays of dates and times: just as lists of Python numerical variables are suboptimal compared to NumPy-style typed numerical arrays, lists of Python datetime objects are suboptimal compared to typed arrays of encoded dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Time Series Data in `NumPy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date5 = np.array('2019-05-07', dtype=np.datetime64)\n",
    "date5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the date object in a Numpy format, we can perform vectorized operations on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date5-np.arange(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pandas` for Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we will focus on the datetime functionality provided by Pandas. Pandas builds upon all the tools above to provide a `Timestamp` object, which combines the ease-of-use of datetime with the efficient storage and vectorized interface of `numpy.datetime64`. From a group of these Timestamp objects, Pandas can construct a `DatetimeIndex` that can be used to index data in a Series or DataFrame; we'll see how this works below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas was developed in the context of financial modeling, so as you might expect, it contains a fairly extensive set of tools for working with dates, times, and time-indexed data. Date and time data comes in a few forms, which we will discuss here:\n",
    "* __Time stamps__ reference particular moments in time (e.g., May 7th, 2019 at 4:00pm).\n",
    "* __Time intervals__ and periods reference a length of time between a particular beginning and end point; for example, the year 2015. Periods usually reference a special case of time intervals in which each interval is of uniform length and does not overlap (e.g., 24 hour-long periods comprising days).\n",
    "* __Time deltas__ or durations reference an exact length of time (e.g., a duration of 22.56 seconds).\n",
    "\n",
    "In the following we will introduce how to work with each of these types of date/time data in Python/Pandas. This short section is by no means a complete guide to the time series tools available in Python or Pandas, but will equip you with the relevat methods and techniques necessary to complete your team assignments. \n",
    "\n",
    "We will keep theory very short and focus instead on key methods relevant to your assignment by using the real-world example of German power prices. For more information on this please consult the relevant Pandas documentation [here](http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a date and return the respective timestamp\n",
    "date6 = pd.to_datetime(\"7th of May, 2019\")\n",
    "date7 = pd.to_datetime(\"07.05.2019\",format=\"%d.%m.%Y\") # the format argument defines the format in which the data comes in\n",
    "print(date6)\n",
    "print(date7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the type\n",
    "type(date6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also return important relevant time features, such as the weekday\n",
    "date6.weekday() # The day of the week with Monday=0, Sunday=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or the year\n",
    "date6.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or the hour\n",
    "date6.hour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas` Intervals/Periods\n",
    "For time periods, Pandas provides the Period type. This encodes a fixed-frequency interval based on numpy.datetime64. The associated index structure is PeriodIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify start point and end point or number of periods with associated frequency\n",
    "date_index3 = pd.date_range(start=datetime(year=2019, month=5, day=7), periods=8, freq=\"2H\")\n",
    "date_index3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can adjust the frequency which defaults to D (i.e. days)\n",
    "date_index4 = pd.date_range(start=datetime(year=2019, month=1, day=1), end=datetime(year=2020, month=1, day=1), freq=\"H\")\n",
    "date_index4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas` Timedelta\n",
    "For time deltas or durations, Pandas provides the Timedelta type. Timedelta is a more efficient replacement for Python's native datetime.timedelta type, and is based on numpy.timedelta64. The associated index structure is TimedeltaIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define another date and determine the time delta from the orginal date through simple substraction. The result is a Timedelta object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date7 = pd.to_datetime(datetime(year=2019, month=5, day=14))\n",
    "print(date7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta = date7-date6\n",
    "print(time_delta)\n",
    "print(type(time_delta))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Example - Power Price Data\n",
    "A common example in the domain of sustainability is power price analysis. We will go through a simple example using daily power price data from 2008 to 2018. We will use the `Pandas` library to work with this data. We will do four things:\n",
    "\n",
    "- Indexing of time series data\n",
    "- Aggregating time series data\n",
    "- Handling missing data in time series\n",
    "- Extracting temporal features from time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in power price data\n",
    "Power_prices = pd.read_csv(\"EEX_baseload_future.csv\", delimiter=\";\", decimal=\",\")\n",
    "Power_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the data type of the Date column\n",
    "Power_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Date column to datetime\n",
    "Power_prices[\"Date\"] = pd.to_datetime(Power_prices[\"Date\"], format=\"%d.%m.%y\")\n",
    "Power_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note new data type of Date column\n",
    "Power_prices.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For the time being we will work with `Closing_Price` for which there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "ax.plot(Power_prices[\"Date\"],Power_prices[\"Closing_Price\"])\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"EUR/MWh\")\n",
    "ax.set_title(\"EEX Power Phelix Baseload Year Future\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing time series data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose we only want to look at one specific year - say 2017. Since Pandas has a built-in datetime functionality we can perform boolean operations on the dates, which allows us to specify the desired interval through masking. In the following, we create a new DataFrame for 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Create a new DataFrame entitled `Power_prices_17` which contains only values of the year 2017. To do so, define two datetime variables to mark the upper and lower bound of the period you are interested in. Then use pandas masking techniques to index the desired period and assign it to the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# define start and end datetime variables\n",
    "\n",
    "\n",
    "# create Power_prices_17 dataframe through masking\n",
    "\n",
    "\n",
    "# sort values by date\n",
    "\n",
    "\n",
    "# examine data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Plot `Power_prices_17`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Create the same plot, but instead of using a separate dataframe for the year 2017, just use the full data and limit the range of the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Time Series Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common need for time series data is resampling at a higher or lower frequency. This can be done using the `resample()` method, or the much simpler `asfreq()` method. The primary difference between the two is that `resample()` is fundamentally a data aggregation, while `asfreq()` is fundamentally a data selection.\n",
    "Taking a look at the Power closing price, let's compare what the two methods return when we down-sample the data. Here we will resample the data at the end of a business month (BM). The types of frequency or date offsets that can be selected are shown in the below table. By adding an S suffix, instead of the end of a period, the start is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Code   | Description         | Code   | Description          |\n",
    "|--------|---------------------|--------|----------------------|\n",
    "| ``D``  | Calendar day        | ``B``  | Business day         |\n",
    "| ``W``  | Weekly              |        |                      |\n",
    "| ``M``  | Month end           | ``BM`` | Business month end   |\n",
    "| ``Q``  | Quarter end         | ``BQ`` | Business quarter end |\n",
    "| ``A``  | Year end            | ``BA`` | Business year end    |\n",
    "| ``H``  | Hours               | ``BH`` | Business hours       |\n",
    "| ``T``  | Minutes             |        |                      |\n",
    "| ``S``  | Seconds             |        |                      |\n",
    "| ``L``  | Milliseonds         |        |                      |\n",
    "| ``U``  | Microseconds        |        |                      |\n",
    "| ``N``  | nanoseconds         |        |                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember our data\n",
    "Power_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for these techniques to work we need a datetime index\n",
    "Power_prices_index = Power_prices.set_index(\"Date\")\n",
    "\n",
    "Power_prices_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's resample\n",
    "Power_prices_monthly_resample = Power_prices_index.resample('BM').mean()\n",
    "\n",
    "Power_prices_monthly_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try the same with the .asfreq() method\n",
    "# note that for the .asfreq() command to work properly we need to sort the index first (see below)\n",
    "# we use the ffill method to fill empty values \n",
    "Power_prices_monthly_freq = Power_prices_index.sort_index().asfreq(freq='BM', method=\"ffill\")\n",
    "\n",
    "Power_prices_monthly_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference: at each point, resample reports the average of the previous month (BM), while asfreq reports the value at the end of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "ax.plot(Power_prices_index[\"Closing_Price\"], label=\"Daily\") # daily\n",
    "ax.plot(Power_prices_monthly_resample[\"Closing_Price\"], label=\"BM resampled\") # monthly resampling\n",
    "ax.plot(Power_prices_monthly_freq[\"Closing_Price\"], \"-.\", label=\"BM asfreq\") # monthly freq approach\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"EUR/MWh\")\n",
    "ax.set_title(\"EEX Power Phelix Baseload Year Future\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Resample for a business year and plot the results for `Closing_Price`. What do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# create data frame\n",
    "\n",
    "\n",
    "# plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data in Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various methods exist for time series imputation. Below is an overview\n",
    "\n",
    "**Non-time-series specific method**\n",
    "- mean imputation\n",
    "- median imputation\n",
    "- mode imputation\n",
    "- ...\n",
    "\n",
    "**Time-series specific method**\n",
    "- Last observation carried forward (LOCF)\n",
    "- Next observation carried backward (NOCB)\n",
    "- Linear interpolation\n",
    "- Spline interpolation\n",
    "\n",
    "For reasons of time we will look here at mean and median imputation as well as LOCF (`ffill()`) and NOCB (`bfill()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "Power_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's focus on Opening_Price\n",
    "\n",
    "# fill mean\n",
    "Power_prices[\"Opening_Price\"].fillna(Power_prices[\"Opening_Price\"].mean())\n",
    "\n",
    "# fill median\n",
    "Power_prices[\"Opening_Price\"].fillna(Power_prices[\"Opening_Price\"].median())\n",
    "\n",
    "# forward fill (LOCF)\n",
    "Power_prices[\"Opening_Price\"].fillna(method=\"ffill\")\n",
    "\n",
    "# backward fill (NOCB) \n",
    "Power_prices[\"Opening_Price\"] = Power_prices[\"Opening_Price\"].fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Create a new DataFrame entitled `Power_prices_clean` where you fill all missing values using the forward fill method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the newly created dataframe\n",
    "Power_prices_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power_prices_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: For more sophisticated filling methods have a look at the built-in Pandas `interpolate()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wish to extract some temporal features for use in a machine learning model. This may be the case if time carries significant explanatory value for the dependent variable, as is the case in many real-world settings.\n",
    "\n",
    "For illustrative pruposes let us stick with our price dataset. Suppose price is a function of the type of day, i.e. whether it is a Monday or a Friday. Let us extract a temporal feature set that carries this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weekday using apply and lambda\n",
    "Power_prices[\"Day_of_Week\"] = Power_prices[\"Date\"].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power_prices.sort_values(by=\"Date\", inplace=True)\n",
    "Power_prices.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What type of data is the `Day_of_week` feature? Ordinal, nominal, interval or a ratio? Can it be used like this in a regression model? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the `Day_of_week` feature into a format which is usable in regression models we use a technique which is often referred to as one-hot-encoding. In essence we use a binary encoding to identify the type of day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for Day_of_week feature\n",
    "days = pd.get_dummies(Power_prices[\"Day_of_Week\"],prefix=\"Day\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join it with the original DF\n",
    "Power_prices[list(days.columns)] = days # alternatively you can also use df.join()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other typically used temporal features iclude:\n",
    "- hour-of-day\n",
    "- weekday y/n\n",
    "- bank holiday y/n\n",
    "- school holidays y/n\n",
    "- lagged time features (e.g. dependent variable 24h ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get lagged features we can use pd.shift(), or groupby().diff()\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.diff.html\n",
    "\n",
    "# for illustrative purposes let us create a lagged feature\n",
    "# Closing_Price_t-1, i.e., the closing price one period (i.e., 1 day ago)\n",
    "\n",
    "# first sort (this ensures the shifting is correct)\n",
    "Power_prices.sort_values(by=\"Date\", inplace=True)\n",
    "\n",
    "# then shift column and assign to new variable\n",
    "Power_prices[\"Closing_Price_t-1\"]= Power_prices[\"Closing_Price\"].shift(periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
